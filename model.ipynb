{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (497, 10) , validate:  (214, 10) , test:  (178, 10)\n"
     ]
    }
   ],
   "source": [
    "#loading the prepped titanic data and \n",
    "#splitting it into train, validate, and test \n",
    "train, validate, test = prep_titanic_data()\n",
    "print(\"train: \", train.shape, \", validate: \", validate.shape, \", test: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass        age  sibsp  parch      fare  alone  sex_male  \\\n",
       "583         0       1  36.000000      0      0   40.1250      1         1   \n",
       "337         1       1  41.000000      0      0  134.5000      1         0   \n",
       "50          0       3   7.000000      4      1   39.6875      0         1   \n",
       "218         1       1  32.000000      0      0   76.2917      1         0   \n",
       "31          1       1  29.916875      1      0  146.5208      0         0   \n",
       "\n",
       "     embarked_Q  embarked_S  \n",
       "583           0           0  \n",
       "337           0           0  \n",
       "50            0           1  \n",
       "218           0           0  \n",
       "31            0           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by defining your baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.617706\n",
       "1    0.382294\n",
       "Name: survived, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making a baseline model\n",
    "train.survived.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.916875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass        age  sibsp  parch      fare  alone  sex_male  \\\n",
       "583         0       1  36.000000      0      0   40.1250      1         1   \n",
       "337         1       1  41.000000      0      0  134.5000      1         0   \n",
       "50          0       3   7.000000      4      1   39.6875      0         1   \n",
       "218         1       1  32.000000      0      0   76.2917      1         0   \n",
       "31          1       1  29.916875      1      0  146.5208      0         0   \n",
       "\n",
       "     embarked_Q  embarked_S  \n",
       "583           0           0  \n",
       "337           0           0  \n",
       "50            0           1  \n",
       "218           0           0  \n",
       "31            0           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking a peak at the data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model from Curriculum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an example model based of the curriculum\n",
    "X_train = train[['pclass', 'age', 'fare', 'sibsp', 'parch']]\n",
    "y_train = train[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling the Logistic Regression function and saving it \n",
    "#under the variable called logit for shorthand\n",
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the train dataframe into a logistic regression model\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.98505432 -0.02975293  0.00233927 -0.17750706  0.32613578]]\n",
      "Intercept: \n",
      " [2.49738603]\n"
     ]
    }
   ],
   "source": [
    "#printing the coefficients of each category \n",
    "#along with the intercept of the function\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.49738603])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'logit.predict' predicts class labels for samples in the parenthesis\n",
    "y_pred = logit.predict(X_train)\n",
    "# 'predict_prob' predicts probability estimates\n",
    "y_pred_proba = logit.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.71\n"
     ]
    }
   ],
   "source": [
    "# 'logit.score' returns the mean accuracy on the given test data and labels.\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[262  45]\n",
      " [100  90]]\n"
     ]
    }
   ],
   "source": [
    "#creates a confusion matrix to see how accurate the model is\n",
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.85      0.78       307\n",
      "           1       0.67      0.47      0.55       190\n",
      "\n",
      "    accuracy                           0.71       497\n",
      "   macro avg       0.70      0.66      0.67       497\n",
      "weighted avg       0.70      0.71      0.70       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report to get all scores in an easy to read table\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all of the models you create, choose a threshold that optimizes for accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. Add, commit, and push your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Create another model that includes age in addition to fare and pclass. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing the parameters for another model\n",
    "X1_train = train[['age', 'fare', 'pclass']]\n",
    "y1_train = train[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the data into a logisti regression model\n",
    "logit.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.03051881  0.00266519 -0.97983178]]\n",
      "Intercept: \n",
      " [2.52970125]\n"
     ]
    }
   ],
   "source": [
    "#printing the coefficients and intercepts of the model\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'logit.predict' predicts class labels for samples in the parenthesis\n",
    "y1_pred = logit.predict(X1_train)\n",
    "# 'predict_prob' predicts probability estimates\n",
    "y1_pred_proba = logit.predict_proba(X1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.72\n"
     ]
    }
   ],
   "source": [
    "# 'logit.score' returns the mean accuracy on the given test data and labels.\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X1_train, y1_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[265  42]\n",
      " [ 99  91]]\n"
     ]
    }
   ],
   "source": [
    "#creates a confusion matrix to see how accurate the model is\n",
    "print(confusion_matrix(y1_train, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.86      0.79       307\n",
      "           1       0.68      0.48      0.56       190\n",
      "\n",
      "    accuracy                           0.72       497\n",
      "   macro avg       0.71      0.67      0.68       497\n",
      "weighted avg       0.71      0.72      0.70       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report to get all scores in an easy to read table\n",
    "print(classification_report(y1_train, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does this model perform better than your previous one?\n",
    "\n",
    "It performed slightly better than the previous model. It seems that the coefficients of 'sibsp' and 'parch' did not have much of an effect on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rinse and repeat for the next few models to test different variables\n",
    "X2_train = train[['age', 'fare', 'pclass', 'sex_male']]\n",
    "y2_train = train[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-2.66594879e-02  9.02716903e-04 -1.11402368e+00 -2.45878213e+00]]\n",
      "Intercept: \n",
      " [4.30664987]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred = logit.predict(X2_train)\n",
    "y2_pred_proba = logit.predict_proba(X2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X2_train, y2_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[263  44]\n",
      " [ 56 134]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y2_train, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       307\n",
      "           1       0.75      0.71      0.73       190\n",
      "\n",
      "    accuracy                           0.80       497\n",
      "   macro avg       0.79      0.78      0.78       497\n",
      "weighted avg       0.80      0.80      0.80       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y2_train, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3_train = train[['age', 'fare', 'pclass', 'embarked_Q', 'embarked_S']]\n",
    "y3_train = train[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X3_train, y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.03100806  0.00234461 -1.02568769  0.54782748 -0.15070561]]\n",
      "Intercept: \n",
      " [2.72357442]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y3_pred = logit.predict(X3_train)\n",
    "y3_pred_proba = logit.predict_proba(X3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.71\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X3_train, y3_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[266  41]\n",
      " [101  89]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y3_train, y3_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79       307\n",
      "           1       0.68      0.47      0.56       190\n",
      "\n",
      "    accuracy                           0.71       497\n",
      "   macro avg       0.70      0.67      0.67       497\n",
      "weighted avg       0.71      0.71      0.70       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y3_train, y3_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4_train = train[['age', 'fare', 'pclass', 'alone']]\n",
    "y4_train = train[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X4_train, y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-2.41114976e-02  7.86427878e-04 -9.59730818e-01 -7.85463207e-01]]\n",
      "Intercept: \n",
      " [2.81126777]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y4_pred = logit.predict(X4_train)\n",
    "y4_pred_proba = logit.predict_proba(X4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.72\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X4_train, y4_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[260  47]\n",
      " [ 94  96]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y4_train, y4_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.79       307\n",
      "           1       0.67      0.51      0.58       190\n",
      "\n",
      "    accuracy                           0.72       497\n",
      "   macro avg       0.70      0.68      0.68       497\n",
      "weighted avg       0.71      0.72      0.71       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y4_train, y4_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5_train = train[['age', 'fare', 'sex_male', 'alone']]\n",
    "y5_train = train[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X5_train, y5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-2.10571953e-03  9.81503198e-03 -2.25962521e+00 -1.90950778e-01]]\n",
      "Intercept: \n",
      " [0.78850085]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y5_pred = logit.predict(X5_train)\n",
    "y5_pred_proba = logit.predict_proba(X5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.78\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X5_train, y5_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[261  46]\n",
      " [ 63 127]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y5_train, y5_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       307\n",
      "           1       0.73      0.67      0.70       190\n",
      "\n",
      "    accuracy                           0.78       497\n",
      "   macro avg       0.77      0.76      0.76       497\n",
      "weighted avg       0.78      0.78      0.78       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y5_train, y5_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X6_train = train[['age', 'pclass', 'sex_male', 'alone']]\n",
    "y6_train = train[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X6_train, y6_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.02570129 -1.12720398 -2.41479961 -0.17176794]]\n",
      "Intercept: \n",
      " [4.4084933]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y6_pred = logit.predict(X6_train)\n",
    "y6_pred_proba = logit.predict_proba(X6_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X6_train, y6_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[264  43]\n",
      " [ 58 132]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y6_train, y6_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       307\n",
      "           1       0.75      0.69      0.72       190\n",
      "\n",
      "    accuracy                           0.80       497\n",
      "   macro avg       0.79      0.78      0.78       497\n",
      "weighted avg       0.79      0.80      0.80       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y6_train, y6_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the accuracy of all six models from above\n",
    "- Model 1: .72\n",
    "- Model 2: .80\n",
    "- Model 3: .71\n",
    "- Model 4: .72\n",
    "- Model 5: .78\n",
    "- Model 6: .80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 best models are model 2, 5 and 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recreating the 3 best training variables from the train models\n",
    "#under the validate datasets to retest with new data\n",
    "X2_validate = validate[['age', 'fare', 'pclass', 'sex_male']]\n",
    "y2_validate = validate[['survived']]\n",
    "\n",
    "X5_validate = validate[['age', 'fare', 'sex_male', 'alone']]\n",
    "y5_validate = validate[['survived']]\n",
    "\n",
    "X6_validate = validate[['age', 'pclass', 'sex_male', 'alone']]\n",
    "y6_validate = validate[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.04587951  0.00467339 -1.12012323 -1.88320059]]\n",
      "Intercept: \n",
      " [4.39626524]\n"
     ]
    }
   ],
   "source": [
    "logit.fit(X2_validate, y2_validate)\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.02817128  0.01992692 -1.85331673  0.38786936]]\n",
      "Intercept: \n",
      " [0.6207659]\n"
     ]
    }
   ],
   "source": [
    "logit.fit(X5_validate, y5_validate)\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.04655122 -1.23266078 -1.95035015  0.11929282]]\n",
      "Intercept: \n",
      " [4.78000967]\n"
     ]
    }
   ],
   "source": [
    "logit.fit(X6_validate, y6_validate)\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = logit.predict(X2_validate)\n",
    "y2_pred_proba = logit.predict_proba(X2_validate)\n",
    "y_pred5 = logit.predict(X5_validate)\n",
    "y5_pred_proba = logit.predict_proba(X5_validate)\n",
    "y_pred6 = logit.predict(X6_validate)\n",
    "y6_pred_proba = logit.predict_proba(X6_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 2\n",
      " 0.6074766355140186\n",
      "model 5\n",
      " 0.5981308411214953\n",
      "model 6\n",
      " 0.7850467289719626\n"
     ]
    }
   ],
   "source": [
    "# printing out the mean accuracy on the given test data and labels\n",
    "print(\"model 2\\n\", logit.score(X2_validate, y2_validate))\n",
    "print(\"model 5\\n\", logit.score(X5_validate, y5_validate))\n",
    "print(\"model 6\\n\", logit.score(X6_validate, y6_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 2\n",
      " [[130   2]\n",
      " [ 82   0]]\n",
      "model 5\n",
      " [[128   4]\n",
      " [ 82   0]]\n",
      "model 6\n",
      " [[115  17]\n",
      " [ 29  53]]\n"
     ]
    }
   ],
   "source": [
    "#printing out a confusion matrix for all models\n",
    "print(\"model 2\\n\", confusion_matrix(y2_validate, y_pred2))\n",
    "print(\"model 5\\n\", confusion_matrix(y5_validate, y_pred5))\n",
    "print(\"model 6\\n\", confusion_matrix(y6_validate, y_pred6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 2\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.98      0.76       132\n",
      "           1       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.61       214\n",
      "   macro avg       0.31      0.49      0.38       214\n",
      "weighted avg       0.38      0.61      0.47       214\n",
      "\n",
      "model 5\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.97      0.75       132\n",
      "           1       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.60       214\n",
      "   macro avg       0.30      0.48      0.37       214\n",
      "weighted avg       0.38      0.60      0.46       214\n",
      "\n",
      "model 6\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83       132\n",
      "           1       0.76      0.65      0.70        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.78      0.76      0.77       214\n",
      "weighted avg       0.78      0.79      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing out a classification report for all models\n",
    "print(\"model 2\\n\", classification_report(y2_validate, y_pred2))\n",
    "print(\"model 5\\n\", classification_report(y5_validate, y_pred5))\n",
    "print(\"model 6\\n\", classification_report(y6_validate, y_pred6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recreating the best train and validate model variables\n",
    "#under the test datasets to run a final test\n",
    "X6_test = test[['age', 'pclass', 'sex_male', 'alone']]\n",
    "y6_test = test[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.03826895 -0.83611527 -2.63666645  0.30714706]]\n",
      "Intercept: \n",
      " [3.92034512]\n"
     ]
    }
   ],
   "source": [
    "logit.fit(X6_test, y6_test)\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8258426966292135\n",
      "[[96 14]\n",
      " [17 51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       110\n",
      "           1       0.78      0.75      0.77        68\n",
      "\n",
      "    accuracy                           0.83       178\n",
      "   macro avg       0.82      0.81      0.81       178\n",
      "weighted avg       0.82      0.83      0.83       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 'logit.predict' predicts class labels for validate samples in the parenthesis\n",
    "y_pred = logit.predict(X6_test)\n",
    "# 'predict_proba' creates probability estimates\n",
    "y_pred_proba = logit.predict_proba(X6_test)\n",
    "\n",
    "# print the mean accuracy on the given test data and labels.\n",
    "accuracy = logit.score(X6_test, y6_test)\n",
    "print(accuracy)\n",
    "\n",
    "#print the confusion matrix and classification report for final analysis\n",
    "print(confusion_matrix(y6_test, y_pred))\n",
    "print(classification_report(y6_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance metrics stayed relaively the same throughout the train, validate and test stage. This would be a great model to predict the survival rate since it is roughly 20 percentage points above the baseline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass  sibsp  parch  alone  sex_male  embarked_Q  embarked_S\n",
       "583       1      0      0      1         1           0           0\n",
       "337       1      0      0      1         0           0           0\n",
       "50        3      4      1      0         1           0           1\n",
       "218       1      0      0      1         0           0           0\n",
       "31        1      1      0      0         0           0           0\n",
       "..      ...    ...    ...    ...       ...         ...         ...\n",
       "313       3      0      0      1         1           0           1\n",
       "636       3      0      0      1         1           0           1\n",
       "222       3      0      0      1         1           0           1\n",
       "485       3      3      1      0         0           0           1\n",
       "553       3      0      0      1         1           0           0\n",
       "\n",
       "[497 rows x 7 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ex = train.drop(columns=['age', 'fare', 'survived'])\n",
    "y_train_ex = train[['survived']]\n",
    "X_train_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the data into a logisti regression model\n",
    "logit.fit(X_train_ex, y_train_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.89320109 -0.47113497 -0.14990043 -1.01531958 -2.41796105  0.37728737\n",
      "  -0.0155336 ]]\n",
      "Intercept: \n",
      " [3.8948907]\n"
     ]
    }
   ],
   "source": [
    "#printing the coefficients of each category \n",
    "#along with the intercept of the function\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'logit.predict' predicts class labels for samples in the parenthesis\n",
    "y_pred_ex = logit.predict(X_train_ex)\n",
    "# 'predict_prob' predicts probability estimates\n",
    "y_pred_proba_ex = logit.predict_proba(X_train_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.79\n"
     ]
    }
   ],
   "source": [
    "# 'logit.score' returns the mean accuracy on the given test data and labels.\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train_ex, y_train_ex)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[262  45]\n",
      " [ 57 133]]\n"
     ]
    }
   ],
   "source": [
    "#creates a confusion matrix to see how accurate the model is\n",
    "print(confusion_matrix(y_train_ex, y_pred_ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84       307\n",
      "           1       0.75      0.70      0.72       190\n",
      "\n",
      "    accuracy                           0.79       497\n",
      "   macro avg       0.78      0.78      0.78       497\n",
      "weighted avg       0.79      0.79      0.79       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report to get all scores in an easy to read table\n",
    "print(classification_report(y_train_ex, y_pred_ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate_ex = validate.drop(columns=['age', 'fare', 'survived'])\n",
    "y_validate_ex = validate[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the data into a logisti regression model\n",
    "logit.fit(X_validate_ex, y_validate_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.87303369 -0.39371458 -0.17907146 -0.66087797 -1.98658939  0.09322755\n",
      "  -0.35107385]]\n",
      "Intercept: \n",
      " [3.6238827]\n"
     ]
    }
   ],
   "source": [
    "#printing the coefficients of each category \n",
    "#along with the intercept of the function\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'logit.predict' predicts class labels for samples in the parenthesis\n",
    "y_pred_ex = logit.predict(X_validate_ex)\n",
    "# 'predict_prob' predicts probability estimates\n",
    "y_pred_proba_ex = logit.predict_proba(X_validate_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "# 'logit.score' returns the mean accuracy on the given test data and labels.\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_validate_ex, y_validate_ex)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[117  15]\n",
      " [ 27  55]]\n"
     ]
    }
   ],
   "source": [
    "#creates a confusion matrix to see how accurate the model is\n",
    "print(confusion_matrix(y_validate_ex, y_pred_ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       132\n",
      "           1       0.79      0.67      0.72        82\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.80      0.78      0.79       214\n",
      "weighted avg       0.80      0.80      0.80       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report to get all scores in an easy to read table\n",
    "print(classification_report(y_validate_ex, y_pred_ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: Use only one model for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ex = test.drop(columns=['age', 'fare', 'survived'])\n",
    "y_test_ex = test[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the data into a logisti regression model\n",
    "logit.fit(X_test_ex, y_test_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.57492301 -0.15517538 -0.13565495 -0.04940023 -2.57086937 -0.72527695\n",
      "  -1.10042851]]\n",
      "Intercept: \n",
      " [3.3083142]\n"
     ]
    }
   ],
   "source": [
    "#printing the coefficients of each category \n",
    "#along with the intercept of the function\n",
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'logit.predict' predicts class labels for samples in the parenthesis\n",
    "y_pred_ex = logit.predict(X_test_ex)\n",
    "# 'predict_prob' predicts probability estimates\n",
    "y_pred_proba_ex = logit.predict_proba(X_test_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.83\n"
     ]
    }
   ],
   "source": [
    "# 'logit.score' returns the mean accuracy on the given test data and labels.\n",
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_test_ex, y_test_ex)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[94 16]\n",
      " [15 53]]\n"
     ]
    }
   ],
   "source": [
    "#creates a confusion matrix to see how accurate the model is\n",
    "print(confusion_matrix(y_test_ex, y_pred_ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86       110\n",
      "           1       0.77      0.78      0.77        68\n",
      "\n",
      "    accuracy                           0.83       178\n",
      "   macro avg       0.82      0.82      0.82       178\n",
      "weighted avg       0.83      0.83      0.83       178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report to get all scores in an easy to read table\n",
    "print(classification_report(y_test_ex, y_pred_ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train, y_train):\n",
    "    #importing libraries\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    #defining logistic regression function\n",
    "    logit = LogisticRegression()\n",
    "    #fitting the data into the model\n",
    "    logit.fit(X_train, y_train)\n",
    "    \n",
    "    #creating a list comprehension for the column names\n",
    "    names = [column for column in X_train.columns]\n",
    "    #adding intercept to the end of the list\n",
    "    names.append('intercept')\n",
    "    #creating a dataframe from the regression coefficient values and intercept\n",
    "    coeff = pd.DataFrame(np.append(logit.coef_, logit.intercept_)).T\n",
    "    #renaming the column names with the list of names\n",
    "    coeff.columns = names\n",
    "    \n",
    "    # 'logit.predict' predicts class labels for samples in the parenthesis\n",
    "    y_pred = logit.predict(X_train)\n",
    "    # 'predict_prob' predicts probability estimates\n",
    "    y_pred_proba = logit.predict_proba(X_train)\n",
    "    \n",
    "    #creates a confusion matrix to see how accurate the model is\n",
    "    cm = pd.DataFrame(confusion_matrix(y_train, y_train))\n",
    "    \n",
    "    #creating a copy of y_train\n",
    "    label = y_train\n",
    "    #renaming column in copy of y_train\n",
    "    label = label.rename(columns={label.columns[0]:'label'})\n",
    "    #creating labels out of unique values for \n",
    "    labels = sorted(label.label.unique())\n",
    "    #creating a classification report and saving it as a DataFrame\n",
    "    class_report = pd.DataFrame(classification_report(y_train, y_pred, target_names=labels, output_dict=True))\n",
    "    \n",
    "    return coeff, cm, class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     pclass       age      fare     sibsp     parch  intercept\n",
       " 0 -0.985054 -0.029753  0.002339 -0.177507  0.326136   2.497386,\n",
       "      0    1\n",
       " 0  307    0\n",
       " 1    0  190,\n",
       "                     0           1  accuracy   macro avg  weighted avg\n",
       " precision    0.723757    0.666667  0.708249    0.695212      0.701932\n",
       " recall       0.853420    0.473684  0.708249    0.663552      0.708249\n",
       " f1-score     0.783259    0.553846  0.708249    0.668552      0.695556\n",
       " support    307.000000  190.000000  0.708249  497.000000    497.000000)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepping data for a decision tree\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train[['survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting variable to decision tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the data to the model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'logit.predict' predicts class labels for samples in the parenthesis\n",
    "y_pred = clf.predict(X_train)\n",
    "# 'predict_proba' predicts porbability estimates\n",
    "y_pred_proba = clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "#printing accuracy of the model\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[279,  28],\n",
       "       [ 62, 128]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did not survive</th>\n",
       "      <th>survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>did not survive</th>\n",
       "      <td>279</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survive</th>\n",
       "      <td>62</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 did not survive  survive\n",
       "did not survive              279       28\n",
       "survive                       62      128"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating labels for the confusion matrix\n",
    "labels = ['did not survive', 'survive']\n",
    "\n",
    "#creating a confusion matrix and saving it as a dataframe\n",
    "cm = pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       307\n",
      "           1       0.82      0.67      0.74       190\n",
      "\n",
      "    accuracy                           0.82       497\n",
      "   macro avg       0.82      0.79      0.80       497\n",
      "weighted avg       0.82      0.82      0.81       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creating a classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(279, 28, 62, 128)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identifying and saving the confusion matrix variables \n",
    "TP = cm.iloc[0,0]\n",
    "FN = cm.iloc[0,1]\n",
    "FP = cm.iloc[1,0]\n",
    "TN = cm.iloc[1,1]\n",
    "TP, FN, FP, TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did not survive</th>\n",
       "      <th>survive</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.818913</td>\n",
       "      <td>0.819347</td>\n",
       "      <td>0.819073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.908795</td>\n",
       "      <td>0.673684</td>\n",
       "      <td>0.818913</td>\n",
       "      <td>0.791239</td>\n",
       "      <td>0.818913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.739884</td>\n",
       "      <td>0.818913</td>\n",
       "      <td>0.800498</td>\n",
       "      <td>0.814767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>0.818913</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>497.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           did not survive     survive  accuracy   macro avg  weighted avg\n",
       "precision         0.818182    0.820513  0.818913    0.819347      0.819073\n",
       "recall            0.908795    0.673684  0.818913    0.791239      0.818913\n",
       "f1-score          0.861111    0.739884  0.818913    0.800498      0.814767\n",
       "support         307.000000  190.000000  0.818913  497.000000    497.000000"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating labels for the classification report\n",
    "target_names = ['did not survive', 'survive']\n",
    "\n",
    "#creating the classification report\n",
    "x = classification_report(y_train, y_pred, target_names=target_names, output_dict=True)\n",
    "\n",
    "#saving the report as a dataframe\n",
    "class_report = pd.DataFrame(x)\n",
    "class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#True pos rate\n",
    "TP_rate = round(TP / (TP + FN),3)\n",
    "#False pos rate\n",
    "FP_rate = round(FP / (FP + TN),3)\n",
    "#True neg rate\n",
    "TN_rate = round(TN / (TN + FP),3)\n",
    "#False neg rate\n",
    "FN_rate = round(FN / (FN + TP),3)\n",
    "\n",
    "accuracy = round(accuracy_score(y_true = y_train, y_pred = y_pred),3)\n",
    "precision = round(precision_score(y_true = y_train, y_pred = y_pred),3)\n",
    "recall = round(recall_score(y_true = y_train, y_pred = y_pred),3)\n",
    "f1score = round(f1_score(y_true = y_train, y_pred = y_pred),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Pos Rate: 0.909\n",
      "False Pos Rate: 0.326\n",
      "True Neg Rate: 0.674\n",
      "False Pos Rate: 0.326\n",
      "\n",
      "\n",
      "Accuracy: 0.819\n",
      "Precision: 0.821\n",
      "Recall: 0.674\n",
      "F1-score: 0.74\n"
     ]
    }
   ],
   "source": [
    "print(f'True Pos Rate: {TP_rate}')\n",
    "print(f'False Pos Rate: {FP_rate}')\n",
    "print(f'True Neg Rate: {TN_rate}')\n",
    "print(f'False Pos Rate: {FP_rate}')\n",
    "\n",
    "print('\\n')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = DecisionTreeClassifier(max_depth=9, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=9, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=123, splitter='best')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = clf2.predict(X_train)\n",
    "y_pred_proba2 = clf2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.91\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did not survive</th>\n",
       "      <th>survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>did not survive</th>\n",
       "      <td>294</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survive</th>\n",
       "      <td>30</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 did not survive  survive\n",
       "did not survive              294       13\n",
       "survive                       30      160"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm2 = pd.DataFrame(confusion_matrix(y_train, y_pred2), index=labels, columns=labels)\n",
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294, 30, 13, 160)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = cm2.iloc[0,0]\n",
    "FN = cm2.iloc[0,1]\n",
    "FP = cm2.iloc[1,0]\n",
    "TN = cm2.iloc[1,1]\n",
    "TP, FP, FN, TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did not survive</th>\n",
       "      <th>survive</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.924855</td>\n",
       "      <td>0.913481</td>\n",
       "      <td>0.916131</td>\n",
       "      <td>0.914078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.957655</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.913481</td>\n",
       "      <td>0.899880</td>\n",
       "      <td>0.913481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.931854</td>\n",
       "      <td>0.881543</td>\n",
       "      <td>0.913481</td>\n",
       "      <td>0.906698</td>\n",
       "      <td>0.912620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>0.913481</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>497.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           did not survive     survive  accuracy   macro avg  weighted avg\n",
       "precision         0.907407    0.924855  0.913481    0.916131      0.914078\n",
       "recall            0.957655    0.842105  0.913481    0.899880      0.913481\n",
       "f1-score          0.931854    0.881543  0.913481    0.906698      0.912620\n",
       "support         307.000000  190.000000  0.913481  497.000000    497.000000"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = classification_report(y_train, y_pred2, target_names=target_names, output_dict=True)\n",
    "class_report2 = pd.DataFrame(x2)\n",
    "class_report2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_rate = round(TP / (TP + FN),3)\n",
    "FP_rate = round(FP / (FP + TN),3)\n",
    "TN_rate = round(TN / (TN + FP),3)\n",
    "FN_rate = round(FN / (FN + TP),3)\n",
    "accuracy = round(accuracy_score(y_true = y_train, y_pred = y_pred2),3)\n",
    "precision = round(precision_score(y_true = y_train, y_pred = y_pred2),3)\n",
    "recall = round(recall_score(y_true = y_train, y_pred = y_pred2),3)\n",
    "f1score = round(f1_score(y_true = y_train, y_pred = y_pred2),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Pos Rate: 0.958\n",
      "False Pos Rate: 0.158\n",
      "True Neg Rate: 0.842\n",
      "False Pos Rate: 0.158\n",
      "\n",
      "\n",
      "Accuracy: 0.913\n",
      "Precision: 0.925\n",
      "Recall: 0.842\n",
      "F1-score: 0.882\n"
     ]
    }
   ],
   "source": [
    "print(f'True Pos Rate: {TP_rate}')\n",
    "print(f'False Pos Rate: {FP_rate}')\n",
    "print(f'True Neg Rate: {TN_rate}')\n",
    "print(f'False Pos Rate: {FP_rate}')\n",
    "\n",
    "print('\\n')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree with a higher max depth value performed better on my in_sample data but it may not be the best data for other sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a function to perform decision trees quicker\n",
    "def decision_tree(X_train, y_train, depth_number):\n",
    "    \n",
    "    #setting max depth number for DecisionTreeClassifier\n",
    "    clf = DecisionTreeClassifier(max_depth= depth_number, random_state=123)\n",
    "    \n",
    "    #fitting the data to the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    # 'logit.predict' predicts class labels for samples in the parenthesis\n",
    "    y_pred = clf.predict(X_train)\n",
    "    # 'predict_proba' predicts porbability estimates\n",
    "    y_pred_proba = clf.predict_proba(X_train)\n",
    "    #creating a confusion matrix and storing it in a DataFrame\n",
    "    cm = pd.DataFrame(confusion_matrix(y_train, y_pred))\n",
    "    #creating a copy of y_train\n",
    "    label = y_train\n",
    "    #renaming column in copy of y_train\n",
    "    label = label.rename(columns={label.columns[0]:'label'})\n",
    "    #creating labels out of unique values for \n",
    "    labels = sorted(label.label.unique())\n",
    "    #creating a classification report and saving it as a DataFrame\n",
    "    class_report = pd.DataFrame(classification_report(y_train, y_pred, target_names=labels, output_dict=True))\n",
    "    \n",
    "    return cm, class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_rates(cm):\n",
    "    TP = cm[0][0]\n",
    "    FN = cm[0][1]\n",
    "    FP = cm[1][0]\n",
    "    TN = cm[1][1]\n",
    "    TPrate = round(TP / (TP + FN),3)\n",
    "    FPrate = round(FP / (FP + TN),3)\n",
    "    TNrate = round(TN / (TN + FP),3)\n",
    "    FNrate = round(FN / (FN + TP),3)\n",
    "    return TPrate, FPrate, FNrate, TNrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0   1\n",
       " 0  289  18\n",
       " 1  129  61,\n",
       "                     0           1  accuracy   macro avg  weighted avg\n",
       " precision    0.691388    0.772152  0.704225    0.731770      0.722263\n",
       " recall       0.941368    0.321053  0.704225    0.631210      0.704225\n",
       " f1-score     0.797241    0.453532  0.704225    0.625386      0.665843\n",
       " support    307.000000  190.000000  0.704225  497.000000    497.000000)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree(X_train, y_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0   1\n",
       " 0  290  17\n",
       " 1  114  76,\n",
       "                     0           1  accuracy   macro avg  weighted avg\n",
       " precision    0.717822    0.817204  0.736419    0.767513      0.755815\n",
       " recall       0.944625    0.400000  0.736419    0.672313      0.736419\n",
       " f1-score     0.815752    0.537102  0.736419    0.676427      0.709226\n",
       " support    307.000000  190.000000  0.736419  497.000000    497.000000)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree(X_train, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0    1\n",
       " 0  287   20\n",
       " 1   86  104,\n",
       "                     0           1  accuracy   macro avg  weighted avg\n",
       " precision    0.769437    0.838710   0.78672    0.804073      0.795920\n",
       " recall       0.934853    0.547368   0.78672    0.741111      0.786720\n",
       " f1-score     0.844118    0.662420   0.78672    0.753269      0.774656\n",
       " support    307.000000  190.000000   0.78672  497.000000    497.000000)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree(X_train, y_train, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0    1\n",
       " 0  256   51\n",
       " 1   25  165,\n",
       "                     0           1  accuracy   macro avg  weighted avg\n",
       " precision    0.911032    0.763889  0.847082    0.837460      0.854780\n",
       " recall       0.833876    0.868421  0.847082    0.851149      0.847082\n",
       " f1-score     0.870748    0.812808  0.847082    0.841778      0.848598\n",
       " support    307.000000  190.000000  0.847082  497.000000    497.000000)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree(X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0    1\n",
       " 0  298    9\n",
       " 1   20  170,\n",
       "                     0           1  accuracy   macro avg  weighted avg\n",
       " precision    0.937107    0.949721   0.94165    0.943414      0.941929\n",
       " recall       0.970684    0.894737   0.94165    0.932710      0.941650\n",
       " f1-score     0.953600    0.921409   0.94165    0.937505      0.941294\n",
       " support    307.000000  190.000000   0.94165  497.000000    497.000000)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree(X_train, y_train, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot_data = export_graphviz(model, feature_names= X.columns, class_names= {0:'not survived', 1:'survived'}, rounded=True, filled=True, out_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Exercises\n",
    "\n",
    "Continue working in your model file. Be sure to add, commit, and push your changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['pclass', 'age', 'fare', 'sibsp', 'parch']]\n",
    "y_train = train[['survived']]\n",
    "X_validate = validate[['pclass', 'age', 'fare', 'sibsp', 'parch']]\n",
    "y_validate = validate[['survived']]\n",
    "X_test = test[['pclass', 'age', 'fare', 'sibsp', 'parch']]\n",
    "y_test = test[['survived']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(min_samples_leaf= 1, max_depth = 20, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=20, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_train)\n",
    "y_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.97\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>297</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  297   10\n",
       "1    3  187"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmrf = pd.DataFrame(confusion_matrix(y_train, y_pred))\n",
    "cmrf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       307\n",
      "           1       0.95      0.98      0.97       190\n",
      "\n",
      "    accuracy                           0.97       497\n",
      "   macro avg       0.97      0.98      0.97       497\n",
      "weighted avg       0.97      0.97      0.97       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPrate, FPrate, FNrate, TNrate = confusion_matrix_rates(cmrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = round(accuracy_score(y_true = y_train, y_pred = y_pred),3)\n",
    "precision = round(precision_score(y_true = y_train, y_pred = y_pred),3)\n",
    "recall = round(recall_score(y_true = y_train, y_pred = y_pred),3)\n",
    "f1score = round(f1_score(y_true = y_train, y_pred = y_pred),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Pos Rate: 0.99\n",
      "False Pos Rate: 0.051\n",
      "True Neg Rate: 0.949\n",
      "False Pos Rate: 0.051\n",
      "\n",
      "\n",
      "Accuracy: 0.974\n",
      "Precision: 0.949\n",
      "Recall: 0.984\n",
      "F1-score: 0.966\n"
     ]
    }
   ],
   "source": [
    "print(f'True Pos Rate: {TPrate}')\n",
    "print(f'False Pos Rate: {FPrate}')\n",
    "print(f'True Neg Rate: {TNrate}')\n",
    "print(f'False Pos Rate: {FPrate}')\n",
    "\n",
    "print('\\n')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Run through steps increasing your min_samples_leaf to 5 and decreasing your max_depth to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(min_samples_leaf= 5, max_depth = 3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=3, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=5, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=123,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf2.predict(X_train)\n",
    "y_pred_proba = rf2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>286</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  286   21\n",
       "1   70  120"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmrf2 = pd.DataFrame(confusion_matrix(y_train, y_pred))\n",
    "cmrf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86       307\n",
      "           1       0.85      0.63      0.73       190\n",
      "\n",
      "    accuracy                           0.82       497\n",
      "   macro avg       0.83      0.78      0.79       497\n",
      "weighted avg       0.82      0.82      0.81       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPrate2, FPrate2, FNrate2, TNrate2 = confusion_matrix_rates(cmrf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = round(accuracy_score(y_true = y_train, y_pred = y_pred),3)\n",
    "precision = round(precision_score(y_true = y_train, y_pred = y_pred),3)\n",
    "recall = round(recall_score(y_true = y_train, y_pred = y_pred),3)\n",
    "f1score = round(f1_score(y_true = y_train, y_pred = y_pred),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Pos Rate: 0.803\n",
      "False Pos Rate: 0.149\n",
      "True Neg Rate: 0.851\n",
      "False Pos Rate: 0.149\n",
      "\n",
      "\n",
      "Accuracy: 0.817\n",
      "Precision: 0.851\n",
      "Recall: 0.632\n",
      "F1-score: 0.725\n"
     ]
    }
   ],
   "source": [
    "print(f'True Pos Rate: {TPrate2}')\n",
    "print(f'False Pos Rate: {FPrate2}')\n",
    "print(f'True Neg Rate: {TNrate2}')\n",
    "print(f'False Pos Rate: {FPrate2}')\n",
    "\n",
    "print('\\n')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'min_samples_leaf' is the minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves are at the number set at the 'min_samples_leaf' The first model had the 'min_samples_leaf' at one vs the second model is set at 5. Once the model reaches below 5, it will no longer do any splits, therefore will be less accurate than the model set at 1.\n",
    "\n",
    "The 'max_depth' is the maximum depth of the tree. It will keep splitting if necessary until the 'min_samples_leaf' is reached or until it reaches the max_depth. Since the max_depth of the first model is set at 20 we can will have more branches and better fit the data than the second model that is set at 3. \n",
    "\n",
    "The first first model performes better on the in_sample data because it is overfitting the model. With a higher 'max_depth' and lower 'min_samples_leaf' it is able to make better predictions on the data but it may only apply to the training set and not be representative on the sample as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0    1\n",
       " 0  286   21\n",
       " 1   70  120,\n",
       "                     0           1  accuracy   macro avg  weighted avg\n",
       " precision    0.803371    0.851064  0.816901    0.827217      0.821604\n",
       " recall       0.931596    0.631579  0.816901    0.781588      0.816901\n",
       " f1-score     0.862745    0.725076  0.816901    0.793910      0.810115\n",
       " support    307.000000  190.000000  0.816901  497.000000    497.000000)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_train, y_train, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0   1\n",
       " 0  124   8\n",
       " 1   39  43,\n",
       "                     0          1  accuracy   macro avg  weighted avg\n",
       " precision    0.760736   0.843137  0.780374    0.801937      0.792310\n",
       " recall       0.939394   0.524390  0.780374    0.731892      0.780374\n",
       " f1-score     0.840678   0.646617  0.780374    0.743647      0.766318\n",
       " support    132.000000  82.000000  0.780374  214.000000    214.000000)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_validate, y_validate, 5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0    1\n",
       " 0  291   16\n",
       " 1   59  131,\n",
       "                     0           1  accuracy   macro avg  weighted avg\n",
       " precision    0.831429    0.891156  0.849095    0.861293      0.854262\n",
       " recall       0.947883    0.689474  0.849095    0.818678      0.849095\n",
       " f1-score     0.885845    0.777448  0.849095    0.831646      0.844405\n",
       " support    307.000000  190.000000  0.849095  497.000000    497.000000)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_train, y_train, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0   1\n",
       " 0  123   9\n",
       " 1   36  46,\n",
       "                     0          1  accuracy   macro avg  weighted avg\n",
       " precision    0.773585   0.836364   0.78972    0.804974      0.797640\n",
       " recall       0.931818   0.560976   0.78972    0.746397      0.789720\n",
       " f1-score     0.845361   0.671533   0.78972    0.758447      0.778754\n",
       " support    132.000000  82.000000   0.78972  214.000000    214.000000)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_validate, y_validate, 5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0    1\n",
       " 0  293   14\n",
       " 1   48  142,\n",
       "                     0           1  accuracy   macro avg  weighted avg\n",
       " precision    0.859238    0.910256  0.875252    0.884747      0.878742\n",
       " recall       0.954397    0.747368  0.875252    0.850883      0.875252\n",
       " f1-score     0.904321    0.820809  0.875252    0.862565      0.872395\n",
       " support    307.000000  190.000000  0.875252  497.000000    497.000000)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_train, y_train, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0   1\n",
       " 0  122  10\n",
       " 1   27  55,\n",
       "                     0          1  accuracy   macro avg  weighted avg\n",
       " precision    0.818792   0.846154  0.827103    0.832473      0.829276\n",
       " recall       0.924242   0.670732  0.827103    0.797487      0.827103\n",
       " f1-score     0.868327   0.748299  0.827103    0.808313      0.822335\n",
       " support    132.000000  82.000000  0.827103  214.000000    214.000000)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_validate, y_validate, 5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0    1\n",
       " 0  293   14\n",
       " 1   45  145,\n",
       "                     0           1  accuracy   macro avg  weighted avg\n",
       " precision    0.866864    0.911950  0.881288    0.889407      0.884100\n",
       " recall       0.954397    0.763158  0.881288    0.858778      0.881288\n",
       " f1-score     0.908527    0.830946  0.881288    0.869736      0.878868\n",
       " support    307.000000  190.000000  0.881288  497.000000    497.000000)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_train, y_train, 5, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0   1\n",
       " 0  122  10\n",
       " 1   27  55,\n",
       "                     0          1  accuracy   macro avg  weighted avg\n",
       " precision    0.818792   0.846154  0.827103    0.832473      0.829276\n",
       " recall       0.924242   0.670732  0.827103    0.797487      0.827103\n",
       " f1-score     0.868327   0.748299  0.827103    0.808313      0.822335\n",
       " support    132.000000  82.000000  0.827103  214.000000    214.000000)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_validate, y_validate, 5, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0    1\n",
       " 0  290   17\n",
       " 1   66  124,\n",
       "                     0           1  accuracy   macro avg  weighted avg\n",
       " precision    0.814607    0.879433  0.832998    0.847020      0.839389\n",
       " recall       0.944625    0.652632  0.832998    0.798628      0.832998\n",
       " f1-score     0.874811    0.749245  0.832998    0.812028      0.826808\n",
       " support    307.000000  190.000000  0.832998  497.000000    497.000000)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_train, y_train, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0   1\n",
       " 0  126   6\n",
       " 1   39  43,\n",
       "                     0          1  accuracy   macro avg  weighted avg\n",
       " precision    0.763636   0.877551   0.78972    0.820594      0.807286\n",
       " recall       0.954545   0.524390   0.78972    0.739468      0.789720\n",
       " f1-score     0.848485   0.656489   0.78972    0.752487      0.774916\n",
       " support    132.000000  82.000000   0.78972  214.000000    214.000000)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_validate, y_validate, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0    1\n",
       " 0  294   13\n",
       " 1   70  120,\n",
       "                     0           1  accuracy   macro avg  weighted avg\n",
       " precision    0.807692    0.902256  0.832998    0.854974      0.843843\n",
       " recall       0.957655    0.631579  0.832998    0.794617      0.832998\n",
       " f1-score     0.876304    0.743034  0.832998    0.809669      0.825356\n",
       " support    307.000000  190.000000  0.832998  497.000000    497.000000)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_train, y_train, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0   1\n",
       " 0  121  11\n",
       " 1   41  41,\n",
       "                     0          1  accuracy   macro avg  weighted avg\n",
       " precision    0.746914   0.788462  0.757009    0.767688      0.762834\n",
       " recall       0.916667   0.500000  0.757009    0.708333      0.757009\n",
       " f1-score     0.823129   0.611940  0.757009    0.717535      0.742206\n",
       " support    132.000000  82.000000  0.757009  214.000000    214.000000)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_validate, y_validate, 10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0    1\n",
       " 0  292   15\n",
       " 1   62  128,\n",
       "                     0           1  accuracy   macro avg  weighted avg\n",
       " precision    0.824859    0.895105   0.84507    0.859982      0.851713\n",
       " recall       0.951140    0.673684   0.84507    0.812412      0.845070\n",
       " f1-score     0.883510    0.768769   0.84507    0.826139      0.839645\n",
       " support    307.000000  190.000000   0.84507  497.000000    497.000000)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_train, y_train, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0   1\n",
       " 0  121  11\n",
       " 1   40  42,\n",
       "                     0          1  accuracy   macro avg  weighted avg\n",
       " precision    0.751553   0.792453  0.761682    0.772003      0.767225\n",
       " recall       0.916667   0.512195  0.761682    0.714431      0.761682\n",
       " f1-score     0.825939   0.622222  0.761682    0.724080      0.747879\n",
       " support    132.000000  82.000000  0.761682  214.000000    214.000000)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest(X_validate, y_validate, 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model 1: .817-.780 = .037\n",
    "- Model 2: .849-.790 = .059\n",
    "- Model 3: .875-.827 = .048\n",
    "- Model 4: .881-.827 = .054\n",
    "- Model 5: .833-.790 = .043\n",
    "- Model 6: .833-.757 = .076\n",
    "- Model 7: .845-.762 = .083"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1 had the closest metrics with a difference of 3.7%. Other models perfored better on the training set but had a greater discrepancy on the validate set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train, y_train, min_sample, maximum_depth):\n",
    "    rf = RandomForestClassifier(min_samples_leaf= min_sample , max_depth = maximum_depth, random_state = 123)\n",
    "    rf.fit(X_train,y_train)\n",
    "    y_pred = rf.predict(X_train)\n",
    "    cm = pd.DataFrame(confusion_matrix(y_train, y_pred))\n",
    "    #creating a copy of y_train\n",
    "    label = y_train\n",
    "    #renaming column in copy of y_train\n",
    "    label = label.rename(columns={label.columns[0]:'label'})\n",
    "    #creating labels out of unique values for \n",
    "    labels = sorted(label.label.unique())\n",
    "    #creating a classification report and saving it as a DataFrame\n",
    "    class_report = pd.DataFrame(classification_report(y_train, y_pred, target_names=labels, output_dict=True))\n",
    "    return cm, class_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Exercises\n",
    "\n",
    "Continue working in your model notebook or python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.77\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>256</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1\n",
       "0  256   51\n",
       "1   63  127"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmknn = pd.DataFrame(confusion_matrix(y_train, y_pred))\n",
    "cmknn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.82       307\n",
      "           1       0.71      0.67      0.69       190\n",
      "\n",
      "    accuracy                           0.77       497\n",
      "   macro avg       0.76      0.75      0.75       497\n",
      "weighted avg       0.77      0.77      0.77       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPrate, FPrate, FNrate, TNrate = confusion_matrix_rates(cmknn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = round(accuracy_score(y_true = y_train, y_pred = y_pred),3)\n",
    "precision = round(precision_score(y_true = y_train, y_pred = y_pred),3)\n",
    "recall = round(recall_score(y_true = y_train, y_pred = y_pred),3)\n",
    "f1score = round(f1_score(y_true = y_train, y_pred = y_pred),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Pos Rate: 0.803\n",
      "False Pos Rate: 0.287\n",
      "True Neg Rate: 0.713\n",
      "False Pos Rate: 0.287\n",
      "\n",
      "\n",
      "Accuracy: 0.771\n",
      "Precision: 0.713\n",
      "Recall: 0.668\n",
      "F1-score: 0.69\n"
     ]
    }
   ],
   "source": [
    "print(f'True Pos Rate: {TPrate}')\n",
    "print(f'False Pos Rate: {FPrate}')\n",
    "print(f'True Neg Rate: {TNrate}')\n",
    "print(f'False Pos Rate: {FPrate}')\n",
    "\n",
    "print('\\n')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn10 = KNeighborsClassifier(n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn10.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn10.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN classifier on training set: 0.75\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn10.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  278  29\n",
       "1   94  96"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmknn10 = pd.DataFrame(confusion_matrix(y_train, y_pred))\n",
    "cmknn10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82       307\n",
      "           1       0.77      0.51      0.61       190\n",
      "\n",
      "    accuracy                           0.75       497\n",
      "   macro avg       0.76      0.71      0.71       497\n",
      "weighted avg       0.76      0.75      0.74       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPrate, FPrate, FNrate, TNrate = confusion_matrix_rates(cmknn10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = round(accuracy_score(y_true = y_train, y_pred = y_pred),3)\n",
    "precision = round(precision_score(y_true = y_train, y_pred = y_pred),3)\n",
    "recall = round(recall_score(y_true = y_train, y_pred = y_pred),3)\n",
    "f1score = round(f1_score(y_true = y_train, y_pred = y_pred),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Pos Rate: 0.747\n",
      "False Pos Rate: 0.232\n",
      "True Neg Rate: 0.768\n",
      "False Pos Rate: 0.232\n",
      "\n",
      "\n",
      "Accuracy: 0.753\n",
      "Precision: 0.768\n",
      "Recall: 0.505\n",
      "F1-score: 0.61\n"
     ]
    }
   ],
   "source": [
    "print(f'True Pos Rate: {TPrate}')\n",
    "print(f'False Pos Rate: {FPrate}')\n",
    "print(f'True Neg Rate: {TNrate}')\n",
    "print(f'False Pos Rate: {FPrate}')\n",
    "\n",
    "print('\\n')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0    1\n",
       " 0  269   38\n",
       " 1   49  141,\n",
       "                     0           1  accuracy   macro avg  weighted avg\n",
       " precision    0.845912    0.787709   0.82495    0.816811      0.823662\n",
       " recall       0.876221    0.742105   0.82495    0.809163      0.824950\n",
       " f1-score     0.860800    0.764228   0.82495    0.812514      0.823881\n",
       " support    307.000000  190.000000   0.82495  497.000000    497.000000)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kneighbors(X_train, y_train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0    1\n",
       " 0  256   51\n",
       " 1   63  127,\n",
       "                     0           1  accuracy   macro avg  weighted avg\n",
       " precision    0.802508    0.713483  0.770624    0.757995      0.768474\n",
       " recall       0.833876    0.668421  0.770624    0.751149      0.770624\n",
       " f1-score     0.817891    0.690217  0.770624    0.754054      0.769082\n",
       " support    307.000000  190.000000  0.770624  497.000000    497.000000)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kneighbors(X_train, y_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0   1\n",
       " 0  278  29\n",
       " 1   94  96,\n",
       "                     0           1  accuracy   macro avg  weighted avg\n",
       " precision    0.747312    0.768000  0.752515    0.757656      0.755221\n",
       " recall       0.905537    0.505263  0.752515    0.705400      0.752515\n",
       " f1-score     0.818851    0.609524  0.752515    0.714188      0.738827\n",
       " support    307.000000  190.000000  0.752515  497.000000    497.000000)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kneighbors(X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy on model 1 has a better accuracy than the following 2 models. Model 1 also has a better overall precision and recall. \n",
    "\n",
    "Overall Model 1 has the better fit using the KNN.\n",
    "\n",
    "With less data points to analyze, the data points themselves hold more weight so a more accurate prediction can be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kneighbors(X_train, y_train, n_neighbor):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbor)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_train)\n",
    "    cm = pd.DataFrame(confusion_matrix(y_train, y_pred))\n",
    "    #creating a copy of y_train\n",
    "    label = y_train\n",
    "    #renaming column in copy of y_train\n",
    "    label = label.rename(columns={label.columns[0]:'label'})\n",
    "    #creating labels out of unique values for \n",
    "    labels = sorted(label.label.unique())\n",
    "    #creating a classification report and saving it as a DataFrame\n",
    "    class_report = pd.DataFrame(classification_report(y_train, y_pred, target_names=labels, output_dict=True))\n",
    "    return cm, class_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "For both the iris and the titanic data,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Determine which model (with hyperparameters) performs the best (try reducing the number of features to the top 4 features in terms of information gained for each feature individually)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree(X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(X_train, y_train, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(X_train, y_train, 5, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kneighbors(X_train, y_train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Create a new dataframe with top 4 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = train[['parch', 'pclass', 'sex_male', 'alone']]\n",
    "y_train_final = train[['survived']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "Use the top performing algorithm with the metaparameters used in that model. Create the object, fit, transform on in-sample data, and evaluate the results with the training data. Compare your evaluation metrics with those from the original model (with all the features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Run your final model on your out-of-sample dataframe (test_df). Evaluate the results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
