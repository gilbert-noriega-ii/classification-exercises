{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from acquire import get_titanic_data\n",
    "from prepare import prep_titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prep_titanic_data(get_titanic_data())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['pclass', 'age', 'fare', 'sibsp', 'parch']]\n",
    "y = df[['survived']]\n",
    "\n",
    "x_train_validate, x_test, y_train_validate, y_test = train_test_split(x, y, test_size = .20, random_state = 123)\n",
    "\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train_validate, y_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "print(\"train: \", x_train.shape, \", validate: \", x_validate.shape, \", test: \", x_test.shape)\n",
    "print(\"train: \", y_train.shape, \", validate: \", y_validate.shape, \", test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(x_train)\n",
    "y_pred_proba = logit.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all of the models you create, choose a threshold that optimizes for accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.survived.value_counts(normalize=True)\n",
    "# x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. Add, commit, and push your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "Create another model that includes age in addition to fare and pclass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df[['age', 'fare', 'pclass']]\n",
    "y1 = df[['survived']]\n",
    "\n",
    "x1_train_validate, x1_test, y1_train_validate, y1_test = train_test_split(x1, y1, test_size = .20, random_state = 123, stratify = survived)\n",
    "\n",
    "x1_train, x1_validate, y1_train, y1_validate = train_test_split(x1_train_validate, y1_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "print(\"train: \", x1_train.shape, \", validate: \", x1_validate.shape, \", test: \", x1_test.shape)\n",
    "print(\"train: \", y1_train.shape, \", validate: \", y1_validate.shape, \", test: \", y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.fit(x1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred = logit.predict(x1_train)\n",
    "y1_pred_proba = logit.predict_proba(x1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(x1_train, y1_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y1_train, y1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y1_train, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does this model perform better than your previous one?\n",
    "\n",
    "No, it did not perform bette than the previous model. It seems that the coefficients of 'sibsp' and 'parch' canceled each other out so the model performed identical to the last."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_dummies = pd.get_dummies(df.sex, drop_first=True)\n",
    "df = pd.concat([df, titanic_dummies], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = df[['age', 'fare', 'pclass', 'male']]\n",
    "y2 = df[['survived']]\n",
    "\n",
    "x2_train_validate, x2_test, y2_train_validate, y2_test = train_test_split(x2, y2, test_size = .20, random_state = 123)\n",
    "\n",
    "x2_train, x2_validate, y2_train, y2_validate = train_test_split(x2_train_validate, y2_train_validate, test_size = .30, random_state = 123)\n",
    "\n",
    "print(\"train: \", x2_train.shape, \", validate: \", x2_validate.shape, \", test: \", x2_test.shape)\n",
    "print(\"train: \", y2_train.shape, \", validate: \", y2_validate.shape, \", test: \", y2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit.fit(x2_train, y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred = logit.predict(x2_train)\n",
    "y2_pred_proba = logit.predict_proba(x2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(x2_train, y2_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y2_train, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y2_train, y2_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus1 How do different strategies for handling the missing values in the age column affect model performance?\n",
    "\n",
    "Bonus2: How do different strategies for encoding sex affect model performance?\n",
    "\n",
    "Bonus3: scikit-learn's LogisticRegression classifier is actually applying a regularization penalty to the coefficients by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected.\n",
    "\n",
    "\n",
    "C= .01, .1, 1, 10, 100, 1000\n",
    "\n",
    "Bonus Bonus: how does scaling the data interact with your choice of C?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
